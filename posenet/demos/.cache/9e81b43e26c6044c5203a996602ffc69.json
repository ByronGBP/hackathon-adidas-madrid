{"dependencies":[{"name":"/Users/elvingomez/3lv27/hackathons/Mad/posenet/demos/package.json","includedInParent":true,"mtime":1525707475000},{"name":"/Users/elvingomez/3lv27/hackathons/Mad/posenet/demos/.babelrc","includedInParent":true,"mtime":1525707475000},{"name":"/Users/elvingomez/3lv27/hackathons/Mad/posenet/tsconfig.json","includedInParent":true,"mtime":1525707475000},{"name":"@tensorflow/tfjs","loc":{"line":38,"column":17}},{"name":"./checkpoint_loader","loc":{"line":39,"column":34}},{"name":"./checkpoints","loc":{"line":40,"column":28}},{"name":"./mobilenet","loc":{"line":41,"column":26}},{"name":"./multiPose/decodeMultiplePoses","loc":{"line":42,"column":36}},{"name":"./singlePose/decodeSinglePose","loc":{"line":43,"column":33}},{"name":"./util","loc":{"line":44,"column":21}}],"generated":{"js":"\"use strict\";\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : new P(function (resolve) { resolve(result.value); }).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __generator = (this && this.__generator) || function (thisArg, body) {\n    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\n    return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\n    function verb(n) { return function (v) { return step([n, v]); }; }\n    function step(op) {\n        if (f) throw new TypeError(\"Generator is already executing.\");\n        while (_) try {\n            if (f = 1, y && (t = y[op[0] & 2 ? \"return\" : op[0] ? \"throw\" : \"next\"]) && !(t = t.call(y, op[1])).done) return t;\n            if (y = 0, t) op = [0, t.value];\n            switch (op[0]) {\n                case 0: case 1: t = op; break;\n                case 4: _.label++; return { value: op[1], done: false };\n                case 5: _.label++; y = op[1]; op = [0]; continue;\n                case 7: op = _.ops.pop(); _.trys.pop(); continue;\n                default:\n                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\n                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\n                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\n                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\n                    if (t[2]) _.ops.pop();\n                    _.trys.pop(); continue;\n            }\n            op = body.call(thisArg, _);\n        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\n        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\n    }\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar tf = require(\"@tensorflow/tfjs\");\nvar checkpoint_loader_1 = require(\"./checkpoint_loader\");\nvar checkpoints_1 = require(\"./checkpoints\");\nvar mobilenet_1 = require(\"./mobilenet\");\nvar decodeMultiplePoses_1 = require(\"./multiPose/decodeMultiplePoses\");\nvar decodeSinglePose_1 = require(\"./singlePose/decodeSinglePose\");\nvar util_1 = require(\"./util\");\nfunction toInputTensor(input, inputSize, flipHorizontal) {\n    var imageTensor = tf.fromPixels(input);\n    if (flipHorizontal) {\n        return imageTensor.reverse(1).resizeBilinear([inputSize, inputSize]);\n    }\n    else {\n        return imageTensor.resizeBilinear([inputSize, inputSize]);\n    }\n}\nvar PoseNet = (function () {\n    function PoseNet(mobileNet) {\n        this.mobileNet = mobileNet;\n    }\n    PoseNet.prototype.predictForSinglePose = function (input, outputStride) {\n        var _this = this;\n        if (outputStride === void 0) { outputStride = 16; }\n        mobilenet_1.assertValidOutputStride(outputStride);\n        return tf.tidy(function () {\n            var mobileNetOutput = _this.mobileNet.predict(input, outputStride);\n            var heatmaps = _this.mobileNet.convToOutput(mobileNetOutput, 'heatmap_2');\n            var offsets = _this.mobileNet.convToOutput(mobileNetOutput, 'offset_2');\n            return { heatmapScores: heatmaps.sigmoid(), offsets: offsets };\n        });\n    };\n    PoseNet.prototype.predictForMultiPose = function (input, outputStride) {\n        var _this = this;\n        if (outputStride === void 0) { outputStride = 16; }\n        return tf.tidy(function () {\n            var mobileNetOutput = _this.mobileNet.predict(input, outputStride);\n            var heatmaps = _this.mobileNet.convToOutput(mobileNetOutput, 'heatmap_2');\n            var offsets = _this.mobileNet.convToOutput(mobileNetOutput, 'offset_2');\n            var displacementFwd = _this.mobileNet.convToOutput(mobileNetOutput, 'displacement_fwd_2');\n            var displacementBwd = _this.mobileNet.convToOutput(mobileNetOutput, 'displacement_bwd_2');\n            return {\n                heatmapScores: heatmaps.sigmoid(),\n                offsets: offsets,\n                displacementFwd: displacementFwd,\n                displacementBwd: displacementBwd\n            };\n        });\n    };\n    PoseNet.prototype.estimateSinglePose = function (input, imageScaleFactor, flipHorizontal, outputStride) {\n        if (imageScaleFactor === void 0) { imageScaleFactor = 0.5; }\n        if (flipHorizontal === void 0) { flipHorizontal = false; }\n        if (outputStride === void 0) { outputStride = 16; }\n        return __awaiter(this, void 0, void 0, function () {\n            var _this = this;\n            var resolution, _a, heatmapScores, offsets, pose, scale;\n            return __generator(this, function (_b) {\n                switch (_b.label) {\n                    case 0:\n                        mobilenet_1.assertValidOutputStride(outputStride);\n                        mobilenet_1.assertValidScaleFactor(imageScaleFactor);\n                        resolution = util_1.getValidResolution(imageScaleFactor, input.width, outputStride);\n                        _a = tf.tidy(function () {\n                            var inputTensor = toInputTensor(input, resolution, flipHorizontal);\n                            return _this.predictForSinglePose(inputTensor, outputStride);\n                        }), heatmapScores = _a.heatmapScores, offsets = _a.offsets;\n                        return [4, decodeSinglePose_1.default(heatmapScores, offsets, outputStride)];\n                    case 1:\n                        pose = _b.sent();\n                        heatmapScores.dispose();\n                        offsets.dispose();\n                        scale = input.width / resolution;\n                        return [2, util_1.scalePose(pose, scale)];\n                }\n            });\n        });\n    };\n    PoseNet.prototype.estimateMultiplePoses = function (input, imageScaleFactor, flipHorizontal, outputStride, maxDetections, scoreThreshold, nmsRadius) {\n        if (imageScaleFactor === void 0) { imageScaleFactor = 0.5; }\n        if (flipHorizontal === void 0) { flipHorizontal = false; }\n        if (outputStride === void 0) { outputStride = 16; }\n        if (maxDetections === void 0) { maxDetections = 5; }\n        if (scoreThreshold === void 0) { scoreThreshold = .5; }\n        if (nmsRadius === void 0) { nmsRadius = 20; }\n        return __awaiter(this, void 0, void 0, function () {\n            var _this = this;\n            var resolution, _a, heatmapScores, offsets, displacementFwd, displacementBwd, poses, scale;\n            return __generator(this, function (_b) {\n                switch (_b.label) {\n                    case 0:\n                        mobilenet_1.assertValidOutputStride(outputStride);\n                        mobilenet_1.assertValidScaleFactor(imageScaleFactor);\n                        resolution = util_1.getValidResolution(imageScaleFactor, input.width, outputStride);\n                        _a = tf.tidy(function () {\n                            var inputTensor = toInputTensor(input, resolution, flipHorizontal);\n                            return _this.predictForMultiPose(inputTensor, outputStride);\n                        }), heatmapScores = _a.heatmapScores, offsets = _a.offsets, displacementFwd = _a.displacementFwd, displacementBwd = _a.displacementBwd;\n                        return [4, decodeMultiplePoses_1.default(heatmapScores, offsets, displacementFwd, displacementBwd, outputStride, maxDetections, scoreThreshold, nmsRadius)];\n                    case 1:\n                        poses = _b.sent();\n                        heatmapScores.dispose();\n                        offsets.dispose();\n                        displacementFwd.dispose();\n                        displacementBwd.dispose();\n                        scale = input.width / resolution;\n                        return [2, util_1.scalePoses(poses, scale)];\n                }\n            });\n        });\n    };\n    PoseNet.prototype.dispose = function () {\n        this.mobileNet.dispose();\n    };\n    return PoseNet;\n}());\nexports.PoseNet = PoseNet;\nfunction load(multiplier) {\n    if (multiplier === void 0) { multiplier = 1.01; }\n    return __awaiter(this, void 0, void 0, function () {\n        var possibleMultipliers, checkpoint, checkpointLoader, variables, mobileNet;\n        return __generator(this, function (_a) {\n            switch (_a.label) {\n                case 0:\n                    if (tf == null) {\n                        throw new Error(\"Cannot find TensorFlow.js. If you are using a <script> tag, please \" +\n                            \"also include @tensorflow/tfjs on the page before using this model.\");\n                    }\n                    possibleMultipliers = Object.keys(checkpoints_1.checkpoints);\n                    tf.util.assert(typeof multiplier === 'number', \"got multiplier type of \" + typeof multiplier + \" when it should be a \" +\n                        \"number.\");\n                    tf.util.assert(possibleMultipliers.indexOf(multiplier.toString()) >= 0, \"invalid multiplier value of \" + multiplier + \".  No checkpoint exists for that \" +\n                        (\"multiplier. Must be one of \" + possibleMultipliers.join(',') + \".\"));\n                    checkpoint = checkpoints_1.checkpoints[multiplier];\n                    checkpointLoader = new checkpoint_loader_1.CheckpointLoader(checkpoint.url);\n                    return [4, checkpointLoader.getAllVariables()];\n                case 1:\n                    variables = _a.sent();\n                    mobileNet = new mobilenet_1.MobileNet(variables, checkpoint.architecture);\n                    return [2, new PoseNet(mobileNet)];\n            }\n        });\n    });\n}\nexports.load = load;\n","map":{"version":3,"file":"posenet.js","sourceRoot":"","sources":["../src/posenet.ts"],"names":[],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAiBA,qCAAuC;AAEvC,yDAAqD;AACrD,6CAA0C;AAC1C,yCAA0H;AAC1H,uEAAkE;AAClE,kEAA6D;AAE7D,+BAAiE;AAOjE,uBACI,KAAgB,EAAE,SAAiB,EAAE,cAAuB;IAC9D,IAAM,WAAW,GAAG,EAAE,CAAC,UAAU,CAAC,KAAK,CAAC,CAAC;IAEzC,EAAE,CAAC,CAAC,cAAc,CAAC,CAAC,CAAC;QACnB,MAAM,CAAC,WAAW,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,cAAc,CAAC,CAAC,SAAS,EAAE,SAAS,CAAC,CAAC,CAAC;IACvE,CAAC;IAAC,IAAI,CAAC,CAAC;QACN,MAAM,CAAC,WAAW,CAAC,cAAc,CAAC,CAAC,SAAS,EAAE,SAAS,CAAC,CAAC,CAAC;IAC5D,CAAC;AACH,CAAC;AAED;IAGE,iBAAY,SAAoB;QAC9B,IAAI,CAAC,SAAS,GAAG,SAAS,CAAC;IAC7B,CAAC;IAcD,sCAAoB,GAApB,UAAqB,KAAkB,EAAE,YAA+B;QAAxE,iBAaC;QAbwC,6BAAA,EAAA,iBAA+B;QAEtE,mCAAuB,CAAC,YAAY,CAAC,CAAC;QACtC,MAAM,CAAC,EAAE,CAAC,IAAI,CAAC;YACb,IAAM,eAAe,GAAG,KAAI,CAAC,SAAS,CAAC,OAAO,CAAC,KAAK,EAAE,YAAY,CAAC,CAAC;YAEpE,IAAM,QAAQ,GACV,KAAI,CAAC,SAAS,CAAC,YAAY,CAAC,eAAe,EAAE,WAAW,CAAC,CAAC;YAE9D,IAAM,OAAO,GAAG,KAAI,CAAC,SAAS,CAAC,YAAY,CAAC,eAAe,EAAE,UAAU,CAAC,CAAC;YAEzE,MAAM,CAAC,EAAC,aAAa,EAAE,QAAQ,CAAC,OAAO,EAAE,EAAE,OAAO,SAAA,EAAC,CAAC;QACtD,CAAC,CAAC,CAAC;IACL,CAAC;IAeD,qCAAmB,GAAnB,UAAoB,KAAkB,EAAE,YAA+B;QAAvE,iBA2BC;QA3BuC,6BAAA,EAAA,iBAA+B;QAMrE,MAAM,CAAC,EAAE,CAAC,IAAI,CAAC;YACb,IAAM,eAAe,GAAG,KAAI,CAAC,SAAS,CAAC,OAAO,CAAC,KAAK,EAAE,YAAY,CAAC,CAAC;YAEpE,IAAM,QAAQ,GACV,KAAI,CAAC,SAAS,CAAC,YAAY,CAAC,eAAe,EAAE,WAAW,CAAC,CAAC;YAE9D,IAAM,OAAO,GAAG,KAAI,CAAC,SAAS,CAAC,YAAY,CAAC,eAAe,EAAE,UAAU,CAAC,CAAC;YAEzE,IAAM,eAAe,GACjB,KAAI,CAAC,SAAS,CAAC,YAAY,CAAC,eAAe,EAAE,oBAAoB,CAAC,CAAC;YAEvE,IAAM,eAAe,GACjB,KAAI,CAAC,SAAS,CAAC,YAAY,CAAC,eAAe,EAAE,oBAAoB,CAAC,CAAC;YAEvE,MAAM,CAAC;gBACL,aAAa,EAAE,QAAQ,CAAC,OAAO,EAAE;gBACjC,OAAO,SAAA;gBACP,eAAe,iBAAA;gBACf,eAAe,iBAAA;aAChB,CAAC;QACJ,CAAC,CAAC,CAAC;IACL,CAAC;IA4BK,oCAAkB,GAAxB,UACI,KAAgB,EAAE,gBAA8B,EAChD,cAA+B,EAC/B,YAA+B;QAFb,iCAAA,EAAA,sBAA8B;QAChD,+BAAA,EAAA,sBAA+B;QAC/B,6BAAA,EAAA,iBAA+B;;;;;;;wBACjC,mCAAuB,CAAC,YAAY,CAAC,CAAC;wBACtC,kCAAsB,CAAC,gBAAgB,CAAC,CAAC;wBACnC,UAAU,GACZ,yBAAkB,CAAC,gBAAgB,EAAE,KAAK,CAAC,KAAK,EAAE,YAAY,CAAC,CAAC;wBAE9D,KAA2B,EAAE,CAAC,IAAI,CAAC;4BACvC,IAAM,WAAW,GAAG,aAAa,CAAC,KAAK,EAAE,UAAU,EAAE,cAAc,CAAC,CAAC;4BACrE,MAAM,CAAC,KAAI,CAAC,oBAAoB,CAAC,WAAW,EAAE,YAAY,CAAC,CAAC;wBAC9D,CAAC,CAAC,EAHK,aAAa,mBAAA,EAAE,OAAO,aAAA,CAG1B;wBAEU,WAAM,0BAAgB,CAAC,aAAa,EAAE,OAAO,EAAE,YAAY,CAAC,EAAA;;wBAAnE,IAAI,GAAG,SAA4D;wBAEzE,aAAa,CAAC,OAAO,EAAE,CAAC;wBACxB,OAAO,CAAC,OAAO,EAAE,CAAC;wBAEZ,KAAK,GAAG,KAAK,CAAC,KAAK,GAAG,UAAU,CAAC;wBAEvC,WAAO,gBAAS,CAAC,IAAI,EAAE,KAAK,CAAC,EAAC;;;;KAC/B;IAyCK,uCAAqB,GAA3B,UACI,KAAgB,EAAE,gBAA8B,EAChD,cAA+B,EAAE,YAA+B,EAChE,aAAiB,EAAE,cAAmB,EAAE,SAAc;QAFpC,iCAAA,EAAA,sBAA8B;QAChD,+BAAA,EAAA,sBAA+B;QAAE,6BAAA,EAAA,iBAA+B;QAChE,8BAAA,EAAA,iBAAiB;QAAE,+BAAA,EAAA,mBAAmB;QAAE,0BAAA,EAAA,cAAc;;;;;;;wBACxD,mCAAuB,CAAC,YAAY,CAAC,CAAC;wBACtC,kCAAsB,CAAC,gBAAgB,CAAC,CAAC;wBACnC,UAAU,GACZ,yBAAkB,CAAC,gBAAgB,EAAE,KAAK,CAAC,KAAK,EAAE,YAAY,CAAC,CAAC;wBAC9D,KACF,EAAE,CAAC,IAAI,CAAC;4BACN,IAAM,WAAW,GAAG,aAAa,CAAC,KAAK,EAAE,UAAU,EAAE,cAAc,CAAC,CAAC;4BACrE,MAAM,CAAC,KAAI,CAAC,mBAAmB,CAAC,WAAW,EAAE,YAAY,CAAC,CAAC;wBAC7D,CAAC,CAAC,EAJC,aAAa,mBAAA,EAAE,OAAO,aAAA,EAAE,eAAe,qBAAA,EAAE,eAAe,qBAAA,CAIxD;wBAEO,WAAM,6BAAmB,CACnC,aAAa,EAAE,OAAO,EAAE,eAAe,EAAE,eAAe,EAAE,YAAY,EACtE,aAAa,EAAE,cAAc,EAAE,SAAS,CAAC,EAAA;;wBAFvC,KAAK,GAAG,SAE+B;wBAE7C,aAAa,CAAC,OAAO,EAAE,CAAC;wBACxB,OAAO,CAAC,OAAO,EAAE,CAAC;wBAClB,eAAe,CAAC,OAAO,EAAE,CAAC;wBAC1B,eAAe,CAAC,OAAO,EAAE,CAAC;wBAEpB,KAAK,GAAG,KAAK,CAAC,KAAK,GAAG,UAAU,CAAC;wBAEvC,WAAO,iBAAU,CAAC,KAAK,EAAE,KAAK,CAAC,EAAC;;;;KACjC;IAEM,yBAAO,GAAd;QACE,IAAI,CAAC,SAAS,CAAC,OAAO,EAAE,CAAC;IAC3B,CAAC;IACH,cAAC;AAAD,CAAC,AApMD,IAoMC;AApMY,0BAAO;AAkNpB,cAA2B,UAAsC;IAAtC,2BAAA,EAAA,iBAAsC;;;;;;oBAE/D,EAAE,CAAC,CAAC,EAAE,IAAI,IAAI,CAAC,CAAC,CAAC;wBACf,MAAM,IAAI,KAAK,CACX,qEAAqE;4BACrE,oEAAoE,CAAC,CAAC;oBAC5E,CAAC;oBACK,mBAAmB,GAAG,MAAM,CAAC,IAAI,CAAC,yBAAW,CAAC,CAAC;oBACrD,EAAE,CAAC,IAAI,CAAC,MAAM,CACV,OAAO,UAAU,KAAK,QAAQ,EAC9B,4BAA0B,OAAO,UAAU,0BAAuB;wBAC9D,SAAS,CAAC,CAAC;oBAEnB,EAAE,CAAC,IAAI,CAAC,MAAM,CACV,mBAAmB,CAAC,OAAO,CAAC,UAAU,CAAC,QAAQ,EAAE,CAAC,IAAI,CAAC,EACvD,iCACI,UAAU,sCAAmC;yBAC7C,gCAA8B,mBAAmB,CAAC,IAAI,CAAC,GAAG,CAAC,MAAG,CAAA,CAAC,CAAC;oBAGlE,UAAU,GAAG,yBAAW,CAAC,UAAU,CAAC,CAAC;oBAErC,gBAAgB,GAAG,IAAI,oCAAgB,CAAC,UAAU,CAAC,GAAG,CAAC,CAAC;oBAE5C,WAAM,gBAAgB,CAAC,eAAe,EAAE,EAAA;;oBAApD,SAAS,GAAG,SAAwC;oBAEpD,SAAS,GAAG,IAAI,qBAAS,CAAC,SAAS,EAAE,UAAU,CAAC,YAAY,CAAC,CAAC;oBAEpE,WAAO,IAAI,OAAO,CAAC,SAAS,CAAC,EAAC;;;;CAC/B;AA7BD,oBA6BC","sourcesContent":["/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tf from '@tensorflow/tfjs';\n\nimport {CheckpointLoader} from './checkpoint_loader';\nimport {checkpoints} from './checkpoints';\nimport {assertValidOutputStride, assertValidScaleFactor, MobileNet, MobileNetMultiplier, OutputStride} from './mobilenet';\nimport decodeMultiplePoses from './multiPose/decodeMultiplePoses';\nimport decodeSinglePose from './singlePose/decodeSinglePose';\nimport {Pose} from './types';\nimport {getValidResolution, scalePose, scalePoses} from './util';\n\nexport type PoseNetResolution = 161|193|257|289|321|353|385|417|449|481|513;\n\nexport type InputType =\n    ImageData|HTMLImageElement|HTMLCanvasElement|HTMLVideoElement;\n\nfunction toInputTensor(\n    input: InputType, inputSize: number, flipHorizontal: boolean): tf.Tensor3D {\n  const imageTensor = tf.fromPixels(input);\n\n  if (flipHorizontal) {\n    return imageTensor.reverse(1).resizeBilinear([inputSize, inputSize]);\n  } else {\n    return imageTensor.resizeBilinear([inputSize, inputSize]);\n  }\n}\n\nexport class PoseNet {\n  mobileNet: MobileNet;\n\n  constructor(mobileNet: MobileNet) {\n    this.mobileNet = mobileNet;\n  }\n\n  /**\n   * Infer through PoseNet. This does standard ImageNet pre-processing before\n   * inferring through the model. The image should pixels should have values\n   * [0-255]. This method returns the heatmaps and offsets.  Infers through the\n   * outputs that are needed for single pose decoding\n   *\n   * @param input un-preprocessed input image, with values in range [0-255]\n   * @param outputStride the desired stride for the outputs.  Must be 32, 16,\n   * or 8. Defaults to 16.  The output width and height will be will be\n   * (inputDimension - 1)/outputStride + 1\n   * @return heatmapScores, offsets\n   */\n  predictForSinglePose(input: tf.Tensor3D, outputStride: OutputStride = 16):\n      {heatmapScores: tf.Tensor3D, offsets: tf.Tensor3D} {\n    assertValidOutputStride(outputStride);\n    return tf.tidy(() => {\n      const mobileNetOutput = this.mobileNet.predict(input, outputStride);\n\n      const heatmaps =\n          this.mobileNet.convToOutput(mobileNetOutput, 'heatmap_2');\n\n      const offsets = this.mobileNet.convToOutput(mobileNetOutput, 'offset_2');\n\n      return {heatmapScores: heatmaps.sigmoid(), offsets};\n    });\n  }\n\n  /**\n   * Infer through PoseNet. This does standard ImageNet pre-processing before\n   * inferring through the model. The image should pixels should have values\n   * [0-255]. Infers through the outputs that are needed for multiple pose\n   * decoding. This method returns the heatmaps offsets, and mid-range\n   * displacements.\n   *\n   * @param input un-preprocessed input image, with values in range [0-255]\n   * @param outputStride the desired stride for the outputs.  Must be 32, 16,\n   * or 8. Defaults to 16. The output width and height will be will be\n   * (inputDimension - 1)/outputStride + 1\n   * @return heatmapScores, offsets, displacementFwd, displacementBwd\n   */\n  predictForMultiPose(input: tf.Tensor3D, outputStride: OutputStride = 16): {\n    heatmapScores: tf.Tensor3D,\n    offsets: tf.Tensor3D,\n    displacementFwd: tf.Tensor3D,\n    displacementBwd: tf.Tensor3D\n  } {\n    return tf.tidy(() => {\n      const mobileNetOutput = this.mobileNet.predict(input, outputStride);\n\n      const heatmaps =\n          this.mobileNet.convToOutput(mobileNetOutput, 'heatmap_2');\n\n      const offsets = this.mobileNet.convToOutput(mobileNetOutput, 'offset_2');\n\n      const displacementFwd =\n          this.mobileNet.convToOutput(mobileNetOutput, 'displacement_fwd_2');\n\n      const displacementBwd =\n          this.mobileNet.convToOutput(mobileNetOutput, 'displacement_bwd_2');\n\n      return {\n        heatmapScores: heatmaps.sigmoid(),\n        offsets,\n        displacementFwd,\n        displacementBwd\n      };\n    });\n  }\n\n  /**\n   * Infer through PoseNet, and estimates a single pose using the outputs. This\n   * does standard ImageNet pre-processing before inferring through the model.\n   * The image should pixels should have values [0-255].\n   * This method returns a single pose.\n   *\n   * @param input ImageData|HTMLImageElement|HTMLCanvasElement|HTMLVideoElement)\n   * The input image to feed through the network.\n   *\n   * @param imageScaleFactor A number between 0.2 and 1. Defaults to 0.50. What\n   * to scale the image by before feeding it through the network.  Set this\n   * number lower to scale down the image and increase the speed when feeding\n   * through the network at the cost of accuracy.\n   *\n   * @param flipHorizontal.  Defaults to false.  If the poses should be\n   * flipped/mirrored  horizontally.  This should be set to true for videos\n   * where the video is by default flipped horizontally (i.e. a webcam), and you\n   * want the poses to be returned in the proper orientation.\n   *\n   * @param outputStride the desired stride for the outputs.  Must be 32, 16,\n   * or 8. Defaults to 16. The output width and height will be will be\n   * (inputDimension - 1)/outputStride + 1\n   * @return A single pose with a confidence score, which contains an array of\n   * keypoints indexed by part id, each with a score and position.  The\n   * positions of the keypoints are in the same scale as the original image\n   */\n  async estimateSinglePose(\n      input: InputType, imageScaleFactor: number = 0.5,\n      flipHorizontal: boolean = false,\n      outputStride: OutputStride = 16): Promise<Pose> {\n    assertValidOutputStride(outputStride);\n    assertValidScaleFactor(imageScaleFactor);\n    const resolution =\n        getValidResolution(imageScaleFactor, input.width, outputStride);\n\n    const {heatmapScores, offsets} = tf.tidy(() => {\n      const inputTensor = toInputTensor(input, resolution, flipHorizontal);\n      return this.predictForSinglePose(inputTensor, outputStride);\n    });\n\n    const pose = await decodeSinglePose(heatmapScores, offsets, outputStride);\n\n    heatmapScores.dispose();\n    offsets.dispose();\n\n    const scale = input.width / resolution;\n\n    return scalePose(pose, scale);\n  }\n\n  /**\n   * Infer through PoseNet, and estimates multiple poses using the outputs.\n   * This does standard ImageNet pre-processing before inferring through the\n   * model. The image should pixels should have values [0-255]. It detects\n   * multiple poses and finds their parts from part scores and displacement\n   * vectors using a fast greedy decoding algorithm.  It returns up to\n   * `maxDetections` object instance detections in decreasing root score order.\n   *\n   * @param input ImageData|HTMLImageElement|HTMLCanvasElement|HTMLVideoElement)\n   * The input image to feed through the network.\n   *\n   * @param imageScaleFactor  A number between 0.2 and 1. Defaults to 0.50. What\n   * to scale the image by before feeding it through the network.  Set this\n   * number lower to scale down the image and increase the speed when feeding\n   * through the network at the cost of accuracy.\n   *\n   * @param flipHorizontal Defaults to false.  If the poses should be\n   * flipped/mirrored  horizontally.  This should be set to true for videos\n   * where the video is by default flipped horizontally (i.e. a webcam), and you\n   * want the poses to be returned in the proper orientation.\n   *\n   * @param outputStride the desired stride for the outputs.  Must be 32, 16,\n   * or 8. Defaults to 16. The output width and height will be will be\n   * (inputSize - 1)/outputStride + 1\n   *\n   * @param maxDetections Maximum number of returned instance detections per\n   * image. Defaults to 5.\n   *\n   * @param scoreThreshold Only return instance detections that have root part\n   * score greater or equal to this value. Defaults to 0.5\n   *\n   * @param nmsRadius Non-maximum suppression part distance in pixels. It needs\n   * to be strictly positive. Two parts suppress each other if they are less\n   * than `nmsRadius` pixels away. Defaults to 20.\n   *\n   * @return An array of poses and their scores, each containing keypoints and\n   * the corresponding keypoint scores.  The positions of the keypoints are\n   * in the same scale as the original image\n   */\n  async estimateMultiplePoses(\n      input: InputType, imageScaleFactor: number = 0.5,\n      flipHorizontal: boolean = false, outputStride: OutputStride = 16,\n      maxDetections = 5, scoreThreshold = .5, nmsRadius = 20): Promise<Pose[]> {\n    assertValidOutputStride(outputStride);\n    assertValidScaleFactor(imageScaleFactor);\n    const resolution =\n        getValidResolution(imageScaleFactor, input.width, outputStride);\n    const {heatmapScores, offsets, displacementFwd, displacementBwd} =\n        tf.tidy(() => {\n          const inputTensor = toInputTensor(input, resolution, flipHorizontal);\n          return this.predictForMultiPose(inputTensor, outputStride);\n        });\n\n    const poses = await decodeMultiplePoses(\n        heatmapScores, offsets, displacementFwd, displacementBwd, outputStride,\n        maxDetections, scoreThreshold, nmsRadius);\n\n    heatmapScores.dispose();\n    offsets.dispose();\n    displacementFwd.dispose();\n    displacementBwd.dispose();\n\n    const scale = input.width / resolution;\n\n    return scalePoses(poses, scale);\n  }\n\n  public dispose() {\n    this.mobileNet.dispose();\n  }\n}\n\n/**\n * Loads the PoseNet model instance from a checkpoint, with the MobileNet\n * architecture specified by the multiplier.\n *\n * @param multiplier An optional number with values: 1.01, 1.0, 0.75, or\n * 0.50. Defaults to 1.01. It is the float multiplier for the depth (number of\n * channels) for all convolution ops. The value corresponds to an MobileNet\n * architecture and checkpoint.  The larger the value, the larger the size of\n * the layers, and more accurate the model at the cost of speed.  Set this to a\n * smaller value to increase speed at the cost of accuracy.\n *\n */\nexport async function load(multiplier: MobileNetMultiplier = 1.01):\n    Promise<PoseNet> {\n  if (tf == null) {\n    throw new Error(\n        `Cannot find TensorFlow.js. If you are using a <script> tag, please ` +\n        `also include @tensorflow/tfjs on the page before using this model.`);\n  }\n  const possibleMultipliers = Object.keys(checkpoints);\n  tf.util.assert(\n      typeof multiplier === 'number',\n      `got multiplier type of ${typeof multiplier} when it should be a ` +\n          `number.`);\n\n  tf.util.assert(\n      possibleMultipliers.indexOf(multiplier.toString()) >= 0,\n      `invalid multiplier value of ${\n          multiplier}.  No checkpoint exists for that ` +\n          `multiplier. Must be one of ${possibleMultipliers.join(',')}.`);\n\n  // get the checkpoint for the multiplier\n  const checkpoint = checkpoints[multiplier];\n\n  const checkpointLoader = new CheckpointLoader(checkpoint.url);\n\n  const variables = await checkpointLoader.getAllVariables();\n\n  const mobileNet = new MobileNet(variables, checkpoint.architecture);\n\n  return new PoseNet(mobileNet);\n}\n"]}},"hash":"c596f6c2c870ea364edc63cfb83ce4d7","cacheData":{"env":{}}}